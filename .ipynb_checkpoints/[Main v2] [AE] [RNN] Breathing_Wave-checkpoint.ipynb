{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yokahealthcare/Anasa-GAN/blob/master/%5BMain_v2%5D%20%5BAE%5D%20Breathing_Wave.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mglGdAa9EXAw"
   },
   "source": [
    "# AE - AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bkqs7_K0UFuK"
   },
   "source": [
    "## Project Strucuture\n",
    "\n",
    "### PART 1 : Data Preprocessing\n",
    "\n",
    "\n",
    "1.   Filter the zeros values (except if in the first column)\n",
    "2.   Separate the data(q) according to labels\n",
    "3.   Seperate q into data(X) and label(Y)\n",
    "4.   Normalize the data\n",
    "> X normalized using MinMaxScaler between 0 and 1\n",
    ">\n",
    "> Y normalized using one-hot encoding\n",
    "\n",
    "### PART 2 : Neural Network\n",
    "1.   NN Structure\n",
    "2.   Optimizer : Adam(learning_rate=0.0001)\n",
    "3.   Loss      : MAE (Mean Average Error)\n",
    "\n",
    "### PART 3 : Training\n",
    "1.   Training\n",
    "2.   Smoothing using Savitzky-Golay filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4fC_XBf2xQ-"
   },
   "source": [
    "## PART 1 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edJESBph21is"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lwywzl6DDrXp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMT_LXPvEXVd"
   },
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akXNy_TDEUth"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/yokahealthcare/Anasa-GAN/master/dataset/breathing_waveform_data.csv\").iloc[:, :-1] # get rid of last column (\"notes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJHNMI1EEeNh"
   },
   "source": [
    "### Filter the zeros values\n",
    "> This will filtered the zeros value from all column (except first column)\n",
    ">\n",
    "> CAUSE : I think is natural for the first column to be 0.0 (because the time(X) still on 0 second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3GgDl0dEYOt"
   },
   "outputs": [],
   "source": [
    "zeros_val = df[df.iloc[:, 1:].eq(0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "eIsb07EEEYMi",
    "outputId": "9fdb18cb-9158-4886-fc30-3f536e77361c"
   },
   "outputs": [],
   "source": [
    "zeros_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeZBn2KeEneR"
   },
   "source": [
    "### Drop the table that has value zeros on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxdQlahIEYKT"
   },
   "outputs": [],
   "source": [
    "df = df[~df.isin(zeros_val)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_kSRDlSgEYG_",
    "outputId": "3e4411d8-5600-4cbe-8069-e3d946e165f8"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yslyj_2KFzxZ",
    "outputId": "3ed8f258-bc7e-442f-eb96-e1e1b8d40a70"
   },
   "outputs": [],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DarVtTeFfd_"
   },
   "source": [
    "### Separate the data according to their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_4XvpfzEYBR"
   },
   "outputs": [],
   "source": [
    "normal_df = df[df['labels'] == \"normal\"]\n",
    "quick_df = df[df['labels'] == \"quick\"]\n",
    "hold_df = df[df['labels'] == \"hold\"]\n",
    "deep_df = df[df['labels'] == \"deep\"]\n",
    "deep_quick_df = df[df['labels'] == \"deep_quick\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9hk--KOJNNx"
   },
   "source": [
    "### Seperate the data (X) and the label (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi5q4DpoJLgr"
   },
   "outputs": [],
   "source": [
    "X = normal_df.iloc[:, :-1]\n",
    "Y = normal_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYs6rxwqJESP"
   },
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGMMQAxIJCbM"
   },
   "outputs": [],
   "source": [
    "# Data (X)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsPhN1DHJl0q"
   },
   "outputs": [],
   "source": [
    "# Label (Y)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# encode class values as integers [0,0,0,0,0,0,0,1,1,1,1,1,2,2,2,2]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "hot_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ytoRT3LGmye"
   },
   "source": [
    "# PART 2 : Setup The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DN95tLX5Gue"
   },
   "source": [
    "### Importing Neural Network Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdpxkFBm5GOO"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEn7_dBhZL50"
   },
   "source": [
    "### Neural Network : Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7YWsLKPcGB8",
    "outputId": "ea0683d5-6104-4f94-95a5-cad8f9d96415"
   },
   "outputs": [],
   "source": [
    "feature = 5\n",
    "X_3d = np.reshape(X, (X.shape[0], int(85/feature), feature))\n",
    "# (26400, 17, 5)\n",
    "# 5 indicator will be used per sequence/timestep per sample/row\n",
    "X_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qwTC9C-ZLvW"
   },
   "outputs": [],
   "source": [
    "class AE(Model):\n",
    "    def __init__(self, dropout_rate=0.2, init_mode='glorot_uniform', init_recurrent='orthogonal', init_units=60):\n",
    "      super(AE, self).__init__()\n",
    "\n",
    "      ### Encoder ###\n",
    "      self.encoder = Sequential()\n",
    "\n",
    "      # first layer\n",
    "      self.encoder.add(LSTM(units=init_units, kernel_initializer=init_mode, recurrent_initializer=init_recurrent, return_sequences=True, input_shape=(17, 5)))\n",
    "      self.encoder.add(Dropout(dropout_rate))    # Ignore xx% of the neuron (ex. 50 * 20% = 10 neuoron will be ignored)\n",
    "\n",
    "      # second layer\n",
    "      self.encoder.add(LSTM(units=init_units, return_sequences=True))\n",
    "      self.encoder.add(Dropout(dropout_rate))\n",
    "\n",
    "      # third layer\n",
    "      # self.encoder.add(LSTM(units=20, return_sequences=True))\n",
    "      # self.encoder.add(Dropout(dropout_rate))\n",
    "\n",
    "      # fourth layer\n",
    "      self.encoder.add(LSTM(units=init_units))\n",
    "      self.encoder.add(Dropout(dropout_rate))\n",
    "\n",
    "      # last layer\n",
    "      self.encoder.add(Dense(units=16))\n",
    "      self.encoder.add(Activation(activations.sigmoid))\n",
    "        \n",
    "      \"\"\"\n",
    "      ### Decoder ###\n",
    "      self.decoder = Sequential()\n",
    "\n",
    "      # first layer\n",
    "      self.decoder.add(LSTM(units=init_units, kernel_initializer=init_mode, recurrent_initializer=init_recurrent, return_sequences=True, input_shape=(8, 2)))\n",
    "      self.decoder.add(Dropout(dropout_rate))    # Ignore xx% of the neuron (ex. 50 * 20% = 10 neuoron will be ignored)\n",
    "\n",
    "      # second layer\n",
    "      self.decoder.add(LSTM(units=init_units, return_sequences=True))\n",
    "      self.decoder.add(Dropout(dropout_rate))\n",
    "\n",
    "      # third layer\n",
    "      # self.decoder.add(LSTM(units=20, return_sequences=True))\n",
    "      # self.decoder.add(Dropout(dropout_rate))\n",
    "\n",
    "      # fourth layer\n",
    "      self.decoder.add(LSTM(units=init_units))\n",
    "      self.decoder.add(Dropout(dropout_rate))\n",
    "\n",
    "      # last layer\n",
    "      self.decoder.add(Dense(units=85))\n",
    "      self.decoder.add(Activation(activations.sigmoid))\n",
    "      \"\"\"\n",
    "\n",
    "      \"\"\"\n",
    "      ### Decoder ###\n",
    "      self.decoder = Sequential()\n",
    "      # First Layer\n",
    "      self.decoder.add(Dense(16, input_shape=(17, )))\n",
    "      self.encoder.add(LeakyReLU())\n",
    "      # Second Layer\n",
    "      self.decoder.add(Dense(32))\n",
    "      self.decoder.add(LeakyReLU())\n",
    "      # Third Layer\n",
    "      self.decoder.add(Dense(64))\n",
    "      self.decoder.add(LeakyReLU())\n",
    "      # Fourth Layer\n",
    "      self.decoder.add(Dense(85))\n",
    "      self.decoder.add(Activation(activations.sigmoid))\n",
    "      \"\"\"\n",
    "\n",
    "    def call(self, x):\n",
    "      encoded = self.encoder(x)\n",
    "\n",
    "      print(\"type : {}\".format(type(encoded)))\n",
    "      print(\"shape : {}\".format(encoded.shape))\n",
    "\n",
    "      encoded = tf.reshape(encoded, (None, 8, 2))\n",
    "\n",
    "      decoded = self.decoder(encoded)\n",
    "      return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5tlVknLHDxE"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Create new autoencoder object\n",
    "autoencoder = AE()\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzoHxtnb8CU-"
   },
   "source": [
    "## PART 3 : Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "\n",
    "print(f\"Number of CPU cores: {cpu_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "id": "K-xmwYeUNRgH",
    "outputId": "b19ec599-2c0d-48ac-e034-516c74a4c46f"
   },
   "outputs": [],
   "source": [
    "# Fit the Model\n",
    "with tf.device('/device:CPU:0'):\n",
    "    model = autoencoder.fit(X_3d, X,\n",
    "              epochs=10,\n",
    "              batch_size=32,\n",
    "              shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8VW_0go9FMV"
   },
   "source": [
    "### Plot the training loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "xBc394dYNfGI",
    "outputId": "cd660b05-aecb-4cc4-864d-96b6806a64fd"
   },
   "outputs": [],
   "source": [
    "plt.plot(model.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCtO12xs8f_1"
   },
   "source": [
    "### Define a function to smoothing the wave curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pptqXcSN8a-l"
   },
   "outputs": [],
   "source": [
    "# smoothing the wave of decoded_data\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def smooth_wave(wave):\n",
    "  # Define the parameters for the Savitzky-Golay filter\n",
    "  window_length = 10  # The length of the window (odd number)\n",
    "  polyorder = 2  # The order of the polynomial fit\n",
    "\n",
    "  return savgol_filter(wave, window_length, polyorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFCQHzRs9H1F"
   },
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Uu_aBhlOulH"
   },
   "outputs": [],
   "source": [
    "encoded_data = autoencoder.encoder(X_3d).numpy()\n",
    "decoded_data = autoencoder.decoder(encoded_data).numpy()\n",
    "\n",
    "# Apply the Savitzky-Golay filter\n",
    "decoded_data = smooth_wave(decoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIImf_wE9eZQ"
   },
   "source": [
    "### Calculate the Mean Average Error (MAE) from all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29Ixn4SR_ZDd",
    "outputId": "3a44ac69-3829-4a07-8170-eb931e8e9cb7"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.mae(decoded_data, X)\n",
    "print(\"Mean Average Error : {}\".format(np.mean(loss * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Uc6vII_TU0H"
   },
   "source": [
    "### Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "id": "dAdFN4B2-ER6",
    "outputId": "f42f0f1c-9eb4-4544-f611-cfe4d5c1881e"
   },
   "outputs": [],
   "source": [
    "num_samples = 20\n",
    "row = int(num_samples / 5)\n",
    "\n",
    "# Create figure and axis objects\n",
    "fig, ax = plt.subplots(row, 5, figsize=(20,row*3))\n",
    "\n",
    "idx=0\n",
    "for y in range(row):\n",
    "  for x in range(5):\n",
    "    # Plot each time series\n",
    "    ax[y, x].plot(X[idx], 'b')\n",
    "    ax[y, x].plot(decoded_data[idx], 'g')\n",
    "    ax[y, x].fill_between(np.arange(X.shape[1]), decoded_data[idx], X[idx], color='lightcoral')\n",
    "    ax[y, x].set_title(\"Data {}; err : {:.2f}%\".format(idx, loss[idx]*100))\n",
    "    #ax[y, x].legend()\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "# legend\n",
    "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Customize the overall layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BH6mnrbz4jI"
   },
   "source": [
    "## PART 4 : Generating New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ob4C1KuQPIOR",
    "outputId": "919ae82f-845d-4193-b420-d9f7df47af8f"
   },
   "outputs": [],
   "source": [
    "# Set the number of data points to generate\n",
    "num_samples = 10\n",
    "\n",
    "# Randomly sample latent vectors from a predefined range\n",
    "noise_vectors = np.random.rand(*(num_samples, 85))\n",
    "\n",
    "# Reshape the latent vectors\n",
    "feature = 5\n",
    "noise_vectors = np.reshape(noise_vectors, (noise_vectors.shape[0], int(85/feature), feature))\n",
    "# (26400, 17, 5)\n",
    "# 5 indicator will be used per sequence/timestep per sample/row\n",
    "\n",
    "# Generate new data by decoding the latent vectors\n",
    "generated_data = autoencoder.predict(noise_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "id": "yEVgCWga0GHF",
    "outputId": "1c68eb25-8f58-4a47-d21f-1a35fa001e0f"
   },
   "outputs": [],
   "source": [
    "# Create figure and axis objects\n",
    "row = int(num_samples / 5)\n",
    "\n",
    "fig, ax = plt.subplots(row, 5, figsize=(20,row*3))\n",
    "\n",
    "idx=0\n",
    "for y in range(row):\n",
    "  for x in range(5):\n",
    "    # Plot each time series\n",
    "    ax[y, x].plot(generated_data[idx], 'b')\n",
    "    ax[y, x].set_title(\"Data {}\".format(idx))\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "# legend\n",
    "plt.legend(labels=[\"Generated\"], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# title\n",
    "plt.suptitle(\"Generated Data without Smoothing\")\n",
    "\n",
    "# Customize the overall layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFGqIT4_87kE"
   },
   "source": [
    "## Smoothing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uvs6rFeV0eO7"
   },
   "outputs": [],
   "source": [
    "# Apply the Savitzky-Golay filter\n",
    "generated_data = smooth_wave(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "gSIuhXB-9B69",
    "outputId": "b96dfd79-0cd8-495d-f713-69f9f3dcfc77"
   },
   "outputs": [],
   "source": [
    "# Create figure and axis objects\n",
    "row = int(num_samples / 5)\n",
    "\n",
    "fig, ax = plt.subplots(row, 5, figsize=(20,row*3))\n",
    "\n",
    "idx=0\n",
    "for y in range(row):\n",
    "  for x in range(5):\n",
    "    # Plot each time series\n",
    "    ax[y, x].plot(generated_data[idx], 'b')\n",
    "    ax[y, x].set_title(\"Data {}\".format(idx))\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "# legend\n",
    "plt.legend(labels=[\"Generated\"], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# title\n",
    "plt.suptitle(\"Generated Data with Smoothing\")\n",
    "\n",
    "# Customize the overall layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTfIQd47gT6z5A5NA0O7Ms",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
